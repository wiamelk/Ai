# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VIC-A8hcgvJVf91g61XxU9pJonZw7Na5
"""

# â”€â”€ DonnÃ©es â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
rendements_A = np.array([
    1.2, 0.8, -0.5, 1.5, 0.9, 1.1, 0.7, 1.3, 1.0, 0.6, 1.4, 0.8,
    1.1, 0.9, -0.3, 1.2, 1.0, 1.5, 0.8, 1.3, 0.9, 1.1, 1.2, 1.0
])
rendements_B = np.array([
    4.5, -2.1, 6.2, -3.5, 5.8, 7.1, -1.8, 4.9, 3.2, -4.2, 8.5, -2.7,
    5.1, 6.8, -3.1, 7.3, 4.5, -2.9, 6.7, 5.3, -3.8, 7.9, 4.2, 5.5
])
capital    = 500_000
perte_max  = 50_000
taux_rf    = 3.0

# â”€â”€ Q1.1 â€” Statistiques descriptives â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def calculer_stats(rendements, nom):
    moy_m   = np.mean(rendements)
    std_m   = np.std(rendements, ddof=1)
    med_m   = np.median(rendements)
    r_ann   = ((1 + moy_m / 100) ** 12 - 1) * 100
    vol_ann = std_m * np.sqrt(12)
    return dict(nom=nom, moy_m=moy_m, std_m=std_m, med_m=med_m,
                r_ann=r_ann, vol_ann=vol_ann)

stats_A = calculer_stats(rendements_A, "CONSERVATIVE (A)")
stats_B = calculer_stats(rendements_B, "AGRESSIF (B)")

for s in [stats_A, stats_B]:
    print(f"\nðŸ“Š PORTEFEUILLE {s['nom']}")
    print(f"   â€¢ Rendement mensuel moyen : {s['moy_m']:.2f}%")
    print(f"   â€¢ Ã‰cart-type mensuel      : {s['std_m']:.2f}%")
    print(f"   â€¢ MÃ©diane                 : {s['med_m']:.2f}%")
    print(f"   â€¢ Rendement annualisÃ©     : {s['r_ann']:.2f}%")
    print(f"   â€¢ VolatilitÃ© annualisÃ©e   : {s['vol_ann']:.2f}%")



# â”€â”€ Q1.2 â€” Visualisation distributions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

ax1.hist(rendements_A, bins=10, alpha=0.6, color='green',
         edgecolor='black', label='Portefeuille A', density=True)
ax1.hist(rendements_B, bins=10, alpha=0.6, color='red',
         edgecolor='black', label='Portefeuille B', density=True)
ax1.axvline(stats_A['moy_m'], color='darkgreen', linestyle='--', linewidth=2,
            label=f"Moy A = {stats_A['moy_m']:.2f}%")
ax1.axvline(stats_B['moy_m'], color='darkred', linestyle='--', linewidth=2,
            label=f"Moy B = {stats_B['moy_m']:.2f}%")
ax1.set_title('Distributions rendements mensuels', fontweight='bold')
ax1.set_xlabel('Rendement mensuel (%)'); ax1.set_ylabel('DensitÃ©')
ax1.legend(); ax1.grid(True, alpha=0.3)

bp = ax2.boxplot([rendements_A, rendements_B],
                 labels=['Portefeuille A', 'Portefeuille B'],
                 patch_artist=True, widths=0.6)
for patch, color in zip(bp['boxes'], ['lightgreen', 'lightcoral']):
    patch.set_facecolor(color)
ax2.set_title('Boxplots comparatifs', fontweight='bold')
ax2.set_ylabel('Rendement mensuel (%)')
ax2.axhline(0, color='black', linestyle=':', linewidth=1)
ax2.grid(True, alpha=0.3, axis='y')
plt.tight_layout(); plt.show()

# â”€â”€ Q1.3 â€” VaR 95% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def calculer_var(s, capital, alpha=0.05):
    z          = stats.norm.ppf(alpha)           # â‰ˆ -1.645
    var_m_pct  = s['moy_m']  + z * s['std_m']
    var_a_pct  = s['r_ann']  + z * s['vol_ann']
    return dict(var_m_pct=var_m_pct, var_a_pct=var_a_pct,
                var_m_eur=capital*(var_m_pct/100),
                var_a_eur=capital*(var_a_pct/100))

var_A = calculer_var(stats_A, capital)
var_B = calculer_var(stats_B, capital)

print(f"ðŸ’° Capital : â‚¬{capital:,.0f}  |  Perte max tolÃ©rÃ©e : â‚¬{perte_max:,.0f}")
for lbl, var in [("A (Conservative)", var_A), ("B (Agressif)", var_B)]:
    print(f"\nðŸ“‰ Portefeuille {lbl}")
    print(f"   VaR 95% mensuelle : {var['var_m_pct']:.2f}% â†’ â‚¬{var['var_m_eur']:,.0f}")
    print(f"   VaR 95% annuelle  : {var['var_a_pct']:.2f}% â†’ â‚¬{var['var_a_eur']:,.0f}")

print("\nâœ… Validation contrainte (VaR annuelle â‰¤ -â‚¬50 000) :")
for lbl, var in [("Portefeuille A", var_A), ("Portefeuille B", var_B)]:
    ok = abs(var['var_a_eur']) <= perte_max
    print(f"   {lbl} : {'âœ“ RESPECTÃ‰E' if ok else 'âœ— NON RESPECTÃ‰E'}"
          f"  ({var['var_a_eur']:,.0f} â‚¬)")

# Test Shapiro-Wilk
print("\nðŸ”¬ Test Shapiro-Wilk :")
for lbl, r in [("A", rendements_A), ("B", rendements_B)]:
    w, p = stats.shapiro(r)
    print(f"   Portefeuille {lbl} : W={w:.4f}, p={p:.4f} "
          f"â†’ {'âœ“ Normale' if p > 0.05 else 'âœ— Non normale'}")

# â”€â”€ Q1.4 â€” Ratio Sharpe & recommandation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sharpe_A = (stats_A['r_ann'] - taux_rf) / stats_A['vol_ann']
sharpe_B = (stats_B['r_ann'] - taux_rf) / stats_B['vol_ann']
contrainte_A = abs(var_A['var_a_eur']) <= perte_max
contrainte_B = abs(var_B['var_a_eur']) <= perte_max
_, pA = stats.shapiro(rendements_A)
_, pB = stats.shapiro(rendements_B)

print(f"ðŸ“Š Sharpe A = {sharpe_A:.3f}  |  Sharpe B = {sharpe_B:.3f}\n")
print(f"{'CritÃ¨re':<25} {'Port. A':<18} {'Port. B'}")
print('-' * 60)
print(f"{'Rendement annuel':<25} {stats_A['r_ann']:>8.2f}%        {stats_B['r_ann']:>8.2f}%")
print(f"{'VolatilitÃ© annuelle':<25} {stats_A['vol_ann']:>8.2f}%        {stats_B['vol_ann']:>8.2f}%")
print(f"{'VaR 95% (â‚¬)':<25} {var_A['var_a_eur']:>12,.0f} â‚¬  {var_B['var_a_eur']:>12,.0f} â‚¬")
print(f"{'Contrainte':<25} {'âœ“ OUI' if contrainte_A else 'âœ— NON':<18} {'âœ“ OUI' if contrainte_B else 'âœ— NON'}")
print(f"{'Ratio Sharpe':<25} {sharpe_A:>12.3f}       {sharpe_B:>12.3f}")
print(f"{'NormalitÃ© (p-value)':<25} {pA:>12.4f}       {pB:>12.4f}")

print("\nðŸ’¡ RECOMMANDATION :")
if contrainte_A and not contrainte_B:
    print(f"   âœ… Portefeuille A recommandÃ© â€” seul Ã  respecter VaR â‰¤ -â‚¬50 000")
    print(f"   â†’ Sharpe {sharpe_A:.2f}, volatilitÃ© maÃ®trisÃ©e {stats_A['vol_ann']:.1f}%")
    print(f"   â†’ DonnÃ©es normales â†’ VaR paramÃ©trique fiable")
    print(f"   â†’ Profil adaptÃ© au client conservateur.")

# â”€â”€ DonnÃ©es â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
segments = {
    'Premium':  {'proportion': 0.30, 'taux_defaut': 0.015},
    'Standard': {'proportion': 0.50, 'taux_defaut': 0.05},
    'Risque':   {'proportion': 0.20, 'taux_defaut': 0.15},
}
evenements = {
    'Retard paiement':       {'P_E_D': 0.80, 'P_E_ND': 0.10},
    'DÃ©couvert >500â‚¬':       {'P_E_D': 0.65, 'P_E_ND': 0.15},
    'Refus crÃ©dit ailleurs': {'P_E_D': 0.55, 'P_E_ND': 0.08},
}

# â”€â”€ Q2.1 â€” Calcul Bayes manuel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prior    = segments['Standard']['taux_defaut']      # 5%
P_E_D    = evenements['Retard paiement']['P_E_D']   # 80%
P_E_ND   = evenements['Retard paiement']['P_E_ND']  # 10%

print("ðŸ“‹ Client Segment Standard + Retard de paiement")
print(f"   Prior P(DÃ©faut) = {prior:.1%}")

# Ã‰tape 1 : P(Retard)
P_retard = P_E_D * prior + P_E_ND * (1 - prior)
print(f"\n   Ã‰tape 1 â€” P(Retard) = {P_E_D}Ã—{prior} + {P_E_ND}Ã—{1-prior}")
print(f"            = {P_retard:.4f} = {P_retard:.2%}")

# Ã‰tape 2 : Bayes
posterior_21 = (P_E_D * prior) / P_retard
print(f"\n   Ã‰tape 2 â€” P(DÃ©faut|Retard) = {P_E_D}Ã—{prior} / {P_retard:.4f}")
print(f"            = {posterior_21:.4f} = {posterior_21:.2%}")

facteur = posterior_21 / prior
print(f"\nðŸ“Š Facteur multiplicatif : Ã—{facteur:.2f}")
print(f"   â†’ Retard multiplie le risque par {facteur:.1f} !")

# DÃ©cision mÃ©tier
if posterior_21 < 0.15:
    decision, action = "SURVEILLANCE STANDARD", "Monitoring mensuel"
elif posterior_21 < 0.30:
    decision, action = "SURVEILLANCE RENFORCÃ‰E", "Limite dÃ©couvert -30%"
else:
    decision, action = "RESTRICTION CRÃ‰DIT", "Blocage nouveaux crÃ©dits"
print(f"\nðŸ’¡ DÃ©cision : {decision} â†’ {action}")

# â”€â”€ Q2.2 â€” Mise Ã  jour sÃ©quentielle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prior_2  = posterior_21
P_E_D2   = evenements['DÃ©couvert >500â‚¬']['P_E_D']
P_E_ND2  = evenements['DÃ©couvert >500â‚¬']['P_E_ND']

P_decouvert  = P_E_D2 * prior_2 + P_E_ND2 * (1 - prior_2)
posterior_22 = (P_E_D2 * prior_2) / P_decouvert

print(f"P(DÃ©faut | Retard ET DÃ©couvert) = {posterior_22:.4f} = {posterior_22:.2%}")
print(f"\nÃ‰volution :")
print(f"  Ã‰tape 0 â€” Prior    : {prior:.1%}")
print(f"  Ã‰tape 1 â€” Retard   : {posterior_21:.1%}  (+{(posterior_21-prior)*100:.1f} pts)")
print(f"  Ã‰tape 2 â€” DÃ©couvert: {posterior_22:.1%}  (+{(posterior_22-posterior_21)*100:.1f} pts)")
print(f"  Total : Ã—{posterior_22/prior:.2f} vs prior initial")

# Graphique
etapes = ['0\nPrior\n(Standard 5%)', '1\nAprÃ¨s\nRetard', '2\nAprÃ¨s\nDÃ©couvert']
probas = [prior*100, posterior_21*100, posterior_22*100]
fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(range(3), probas, marker='o', markersize=14, linewidth=3, color='darkred')
for i, p in enumerate(probas):
    ax.annotate(f'{p:.2f}%', xy=(i, p), xytext=(0, 15),
                textcoords='offset points', ha='center', fontsize=11,
                fontweight='bold',
                bbox=dict(boxstyle='round,pad=0.4', facecolor='yellow', alpha=0.8))
ax.axhline(15, color='orange', linestyle='--', linewidth=2,
           label='Seuil surveillance renforcÃ©e (15%)')
ax.axhline(30, color='red',    linestyle='--', linewidth=2,
           label='Seuil restriction crÃ©dit (30%)')
ax.set_xticks(range(3)); ax.set_xticklabels(etapes)
ax.set_ylabel('ProbabilitÃ© de dÃ©faut (%)', fontweight='bold')
ax.set_title('Mise Ã  jour sÃ©quentielle â€” ThÃ©orÃ¨me de Bayes', fontweight='bold')
ax.legend(); ax.grid(True, alpha=0.3)
ax.set_ylim(0, max(probas)*1.4)
plt.tight_layout(); plt.show()

# â”€â”€ Q2.3 â€” Fonction gÃ©nÃ©rique Bayes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def bayes_update(prior, likelihood_pos, likelihood_neg):
    """
    Calcule P(A|B) via le thÃ©orÃ¨me de Bayes.

    Parameters
    ----------
    prior          : float â€” P(A) âˆˆ [0,1]
    likelihood_pos : float â€” P(Evidence|Positif) âˆˆ [0,1]
    likelihood_neg : float â€” P(Evidence|NÃ©gatif) âˆˆ [0,1]

    Returns
    -------
    float â€” P(A|B) posterior

    Examples
    --------
    >>> bayes_update(0.05, 0.80, 0.10)
    0.2963...
    """
    for name, val in [('prior', prior), ('likelihood_pos', likelihood_pos),
                      ('likelihood_neg', likelihood_neg)]:
        if not 0 <= val <= 1:
            raise ValueError(f"{name} doit Ãªtre dans [0,1], reÃ§u {val}")
    p_ev = likelihood_pos * prior + likelihood_neg * (1 - prior)
    if p_ev == 0:
        return 0.0
    return (likelihood_pos * prior) / p_ev

# Test sur Client Segment RISQUE (prior = 15%)
prior_risque = segments['Risque']['taux_defaut']
print(f"ðŸ§ª Test â€” Client Segment RISQUE (prior = {prior_risque:.0%})\n")
p = prior_risque
resultats = {'Prior initial': p}
for nom, data in evenements.items():
    p = bayes_update(p, data['P_E_D'], data['P_E_ND'])
    resultats[f'AprÃ¨s {nom}'] = p
for etape, prob in resultats.items():
    print(f"   {etape:<35} : {prob:.4f}  ({prob:.2%})")
print(f"\n   Multiplication : Ã—{p/prior_risque:.1f} â†’ REJET crÃ©dit recommandÃ©")

# â”€â”€ Q2.4 â€” Matrice confusion et lien Bayes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
n_total, n_defauts = 10_000, 500
TP24, FP24 = 400, 950
FN24 = n_defauts - TP24
TN24 = (n_total - n_defauts) - FP24

precision24 = TP24 / (TP24 + FP24)
print(f"Precision = {TP24}/({TP24}+{FP24}) = {precision24:.4f} = {precision24:.2%}")
print(f"P(DÃ©faut|Retard) Bayes = {posterior_21:.4f} = {posterior_21:.2%}")
print(f"DiffÃ©rence = {abs(posterior_21-precision24):.4f}")
print("""
ðŸ’¡ LIEN BAYES â†” PRECISION :
   Precision = TP/(TP+FP) = P(DÃ©faut rÃ©el | Retard dÃ©tectÃ©)
             = Exactement le posterior bayÃ©sien !
   â†’ Optimiser Precision = maximiser P(Classe|Features) via Bayes
   â†’ Naive Bayes Classifier utilise ce principe explicitement.
""")

# â”€â”€ Q3.1 â€” GÃ©nÃ©ration dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
np.random.seed(42)
n = 2000
age               = np.random.randint(25, 66, n)
salaire           = np.random.normal(50_000, 20_000, n).clip(20_000, 120_000)
anciennete_emploi = np.random.exponential(5, n).clip(0, 30)
dette_totale      = np.random.normal(25_000, 15_000, n).clip(0, 80_000)
ratio_dette       = dette_totale / salaire
nb_credits        = np.random.poisson(1.5, n).clip(0, 5)
hist_retards      = np.random.poisson(2, n).clip(0, 10)
score_credit      = np.random.normal(650, 100, n).clip(300, 850)

defaut_proba = (
    0.05
    + 0.15 * (ratio_dette > 0.5)
    + 0.10 * (hist_retards > 3)
    + 0.08 * (score_credit < 600)
    + 0.05 * (nb_credits > 2)
).clip(0, 0.85)
defaut = (np.random.rand(n) < defaut_proba).astype(int)

df = pd.DataFrame({
    'age': age, 'salaire': salaire,
    'anciennete_emploi': anciennete_emploi,
    'dette_totale': dette_totale,
    'ratio_dette_revenu': ratio_dette,
    'nb_credits_actifs': nb_credits,
    'historique_retards': hist_retards,
    'score_credit_bureau': score_credit,
    'defaut': defaut
})
df.to_csv('credit_data.csv', index=False)
print(f"âœ… Dataset : {len(df)} clients, taux dÃ©faut {defaut.mean():.1%}")
display(df.head())
display(df.describe().round(2))

# Analyse cible et corrÃ©lations
print(f"Taux dÃ©faut : {df['defaut'].mean():.2%}")
print(df['defaut'].value_counts())
corr = df.corr()['defaut'].drop('defaut').sort_values()
print(f"\nCorrÃ©lations avec dÃ©faut :\n{corr.round(4)}")

# Visualisations
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# Heatmap
mask = np.triu(np.ones_like(df.corr(), dtype=bool))
sns.heatmap(df.corr().round(2), annot=True, fmt='.2f', cmap='RdYlGn',
            mask=mask, center=0, linewidths=0.5, ax=ax1, annot_kws={'size': 8})
ax1.set_title('Heatmap des corrÃ©lations', fontweight='bold')
ax1.tick_params(axis='x', rotation=45)

# Boxplots top 2 features
top2 = corr.abs().nlargest(2).index.tolist()
for i, feat in enumerate(top2):
    bp = ax2.boxplot([df.loc[df['defaut']==0, feat], df.loc[df['defaut']==1, feat]],
                     positions=[i*3, i*3+1], widths=0.7, patch_artist=True)
    bp['boxes'][0].set_facecolor('lightblue')
    bp['boxes'][1].set_facecolor('lightcoral')
ax2.set_xticks([0,1,3,4])
ax2.set_xticklabels([f'{top2[0]}\nNon-dÃ©faut', f'{top2[0]}\nDÃ©faut',
                     f'{top2[1]}\nNon-dÃ©faut', f'{top2[1]}\nDÃ©faut'], fontsize=9)
ax2.set_title('Features clÃ©s vs DÃ©faut', fontweight='bold')
ax2.legend(handles=[Patch(facecolor='lightblue', label='Non-dÃ©faut'),
                    Patch(facecolor='lightcoral', label='DÃ©faut')])
ax2.grid(True, alpha=0.3, axis='y')
plt.tight_layout(); plt.show()

# â”€â”€ Q3.2 â€” Preprocessing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X = df.drop(columns=['defaut'])
y = df['defaut']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.30, random_state=42, stratify=y
)
scaler     = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X_test_sc  = scaler.transform(X_test)

print(f"Train : {X_train.shape[0]}  |  Test : {X_test.shape[0]}")
print(f"DÃ©fauts train : {y_train.mean():.2%}  |  DÃ©fauts test : {y_test.mean():.2%}")
print(f"Moyenne aprÃ¨s scaler â‰ˆ 0 : {X_train_sc.mean():.6f}")
print(f"Std    aprÃ¨s scaler â‰ˆ 1 : {X_train_sc.std():.6f}")

# â”€â”€ Q3.3 â€” Optimisation K â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
K_values = [1, 3, 5, 7, 9, 11, 15, 20, 25, 30]
cv_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scoring = {
    'auc':       'roc_auc',
    'recall':    make_scorer(recall_score),
    'precision': make_scorer(precision_score, zero_division=0),
}

rows = []
for k in K_values:
    res = cross_validate(KNeighborsClassifier(n_neighbors=k),
                         X_train_sc, y_train, cv=cv_kf, scoring=scoring)
    rows.append({'K': k,
                 'AUC_mean':       res['test_auc'].mean(),
                 'AUC_std':        res['test_auc'].std(),
                 'Recall_mean':    res['test_recall'].mean(),
                 'Precision_mean': res['test_precision'].mean()})

results_df = pd.DataFrame(rows)
display(results_df.set_index('K').round(4))

best_idx  = results_df['AUC_mean'].idxmax()
K_optimal = int(results_df.loc[best_idx, 'K'])
auc_opt   = results_df.loc[best_idx, 'AUC_mean']
print(f"\nâœ… K OPTIMAL = {K_optimal}  (AUC = {auc_opt:.4f})")

# Graphique AUC vs K
fig, ax = plt.subplots(figsize=(12, 5))
ax.errorbar(results_df['K'], results_df['AUC_mean'],
            yerr=results_df['AUC_std'],
            fmt='-o', linewidth=2, markersize=8,
            color='steelblue', ecolor='lightblue', capsize=5,
            label='AUC moyen Â± std')
ax.axvline(K_optimal, color='red', linestyle='--', linewidth=2,
           label=f'K optimal = {K_optimal}')
ax.scatter([K_optimal], [auc_opt], color='red', s=150, zorder=5)
ax.set_xlabel('K'); ax.set_ylabel('AUC moyen (5-fold CV)')
ax.set_title('Optimisation K par validation croisÃ©e', fontweight='bold')
ax.set_xticks(K_values); ax.legend(); ax.grid(True, alpha=0.3)
plt.tight_layout(); plt.show()

# â”€â”€ Q3.4 â€” Ã‰valuation modÃ¨le final â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
knn = KNeighborsClassifier(n_neighbors=K_optimal)
knn.fit(X_train_sc, y_train)
y_pred       = knn.predict(X_test_sc)
y_pred_proba = knn.predict_proba(X_test_sc)[:, 1]

cm = confusion_matrix(y_test, y_pred)
TN34, FP34, FN34, TP34 = cm.ravel()

print(f"TP={TP34}  FP={FP34}  FN={FN34}  TN={TN34}\n")
print(f"Accuracy    : {accuracy_score(y_test, y_pred):.4f}")
print(f"Precision   : {precision_score(y_test, y_pred, zero_division=0):.4f}")
print(f"Recall      : {recall_score(y_test, y_pred):.4f}")
print(f"F1-Score    : {f1_score(y_test, y_pred):.4f}")
print(f"AUC-ROC     : {roc_auc_score(y_test, y_pred_proba):.4f}")
print(f"SpÃ©cificitÃ© : {TN34/(TN34+FP34):.4f}")
print(f"\n{classification_report(y_test, y_pred, target_names=['Non-DÃ©faut','DÃ©faut'])}")

# Heatmap matrice confusion
fig, ax = plt.subplots(figsize=(7, 5))
labels = np.array([[f'TN\n{TN34}', f'FP\n{FP34}'],
                   [f'FN\n{FN34}', f'TP\n{TP34}']])
sns.heatmap(cm, annot=labels, fmt='', cmap='Blues',
            xticklabels=['PrÃ©dit Non-DÃ©faut','PrÃ©dit DÃ©faut'],
            yticklabels=['RÃ©el Non-DÃ©faut','RÃ©el DÃ©faut'],
            linewidths=1, ax=ax, annot_kws={'size': 13, 'weight': 'bold'})
ax.set_title(f'Matrice de Confusion â€” KNN (K={K_optimal})', fontweight='bold')
plt.tight_layout(); plt.show()

# â”€â”€ Q3.5 â€” Courbe ROC & analyse seuil â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = roc_auc_score(y_test, y_pred_proba)

# Indice Youden
J          = tpr - fpr
youden_idx = np.argmax(J)
seuil_opt  = thresholds[youden_idx]

fig, ax = plt.subplots(figsize=(9, 7))
ax.plot(fpr, tpr, color='steelblue', linewidth=2.5,
        label=f'Courbe ROC (AUC = {roc_auc:.4f})')
ax.plot([0,1],[0,1], 'k--', linewidth=1.5,
        label='AlÃ©atoire (AUC = 0.50)')
ax.scatter([fpr[youden_idx]], [tpr[youden_idx]], color='red', s=150, zorder=5,
           label=f'Youden optimal (seuil = {seuil_opt:.3f})')
ax.annotate(f"  seuil={seuil_opt:.2f}\n  TPR={tpr[youden_idx]:.2f}  FPR={fpr[youden_idx]:.2f}",
            xy=(fpr[youden_idx], tpr[youden_idx]), fontsize=9,
            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))
ax.fill_between(fpr, tpr, alpha=0.1, color='steelblue')
ax.set_xlabel('FPR (1 - SpÃ©cificitÃ©)'); ax.set_ylabel('TPR (Recall)')
ax.set_title(f'Courbe ROC â€” KNN (K={K_optimal})', fontweight='bold')
ax.legend(); ax.grid(True, alpha=0.3)
plt.tight_layout(); plt.show()

# Test 3 seuils
print(f"\n{'Seuil':<8} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Recallâ‰¥80%':>12}")
print('-' * 55)
seuil_results = []
for s in [0.3, 0.5, 0.7]:
    y_s = (y_pred_proba >= s).astype(int)
    p_s = precision_score(y_test, y_s, zero_division=0)
    r_s = recall_score(y_test, y_s)
    f_s = f1_score(y_test, y_s)
    cm_s = confusion_matrix(y_test, y_s).ravel()
    tn_s, fp_s, fn_s, tp_s = cm_s
    ok = 'âœ“' if r_s >= 0.80 else 'âœ—'
    print(f"{s:<8.1f} {p_s:>10.4f} {r_s:>10.4f} {f_s:>10.4f} {ok:>12}")
    seuil_results.append({'seuil': s, 'precision': p_s, 'recall': r_s,
                          'f1': f_s, 'TP': tp_s, 'FP': fp_s, 'FN': fn_s})

# â”€â”€ Q3.6 â€” ROI & Executive Summary (Bonus) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GAIN_TP  = 15_000
COUT_FP  = 500 + 1_200   # analyse + opportunitÃ©
PERTE_FN = 15_000

def roi(tp, fp, fn):
    g = tp * GAIN_TP
    c = fp * COUT_FP
    p = fn * PERTE_FN
    return {'gains': g, 'couts': c, 'pertes': p, 'net': g - c - p}

print(f"{'Seuil':<8} {'TP':>5} {'FP':>5} {'FN':>5} {'Gains':>12} {'CoÃ»ts':>12} {'Pertes':>12} {'ROI NET':>12} {'Recallâ‰¥80%':>12}")
print('-' * 90)
best = None
for sr in seuil_results:
    r = roi(sr['TP'], sr['FP'], sr['FN'])
    ok = 'âœ“' if sr['recall'] >= 0.80 else 'âœ—'
    s  = '+' if r['net'] > 0 else ''
    print(f"{sr['seuil']:<8.1f} {sr['TP']:>5} {sr['FP']:>5} {sr['FN']:>5} "
          f"â‚¬{r['gains']:>10,.0f} â‚¬{r['couts']:>10,.0f} â‚¬{r['pertes']:>10,.0f} "
          f"{s}â‚¬{r['net']:>10,.0f} {ok:>12}")
    if sr['recall'] >= 0.80 and (best is None or r['net'] > best['net']):
        best = {**sr, **r}

seuil_rec = best['seuil'] if best else 0.3
roi_rec   = best['net']   if best else 0

auc_final = roc_auc_score(y_test, y_pred_proba)
prec_final = precision_score(y_test, y_pred, zero_division=0)
rec_final  = recall_score(y_test, y_pred)
f1_final   = f1_score(y_test, y_pred)

print(f"""
{'='*65}
ðŸ“‹ EXECUTIVE SUMMARY â€” DIRECTION
{'='*65}

1. MODÃˆLE RETENU
   KNN avec K={K_optimal} sÃ©lectionnÃ© par CV 5-fold (AUC max = {auc_opt:.3f}).

2. PERFORMANCES CLÃ‰S (set test)
   AUC={auc_final:.3f} | Recall={rec_final:.1%} | Precision={prec_final:.1%} | F1={f1_final:.3f}

3. SEUIL RECOMMANDÃ‰
   Seuil = {seuil_rec} â†’ Recall â‰¥ 80% âœ“ | ROI maximal

4. ROI ANNUEL ESTIMÃ‰
   â‰ˆ +â‚¬{roi_rec:,.0f} sur la base du set de test.
   Gains = dÃ©tection proactive dÃ©fauts (perte Ã©vitÃ©e Ã—â‚¬15 000/dÃ©faut).

5. IMPACT BUSINESS
   â€¢ RÃ©duction pertes crÃ©dit par sÃ©lection amÃ©liorÃ©e
   â€¢ Automatisation dÃ©cisions premier niveau
   â€¢ Alertes prÃ©coces via scoring dynamique
   â€¢ Recommandation : dÃ©ploiement + revue trimestrielle du modÃ¨le
{'='*65}
""")
print("âœ… FIN TP â€” Toutes les parties complÃ©tÃ©es !")